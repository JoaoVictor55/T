\chapter{Resultados e discussões}
\label{ch:resultados}

Nesta seção, serão apresentados os resultados alcançados pelos modelos. Primeiro, a média das métricas com o objetivo de ter uma visão geral do desempenho. 
Em seguida, será feita uma comparação entre as médias na validação com as do treino, para identificar o \textit{overfit}. 
Então, a partir das métricas individuais em cada \textit{fold}, será identificado o pior e o melhor caso de cada modelo utilizando como critério o \textit{f1-score}. 
Apesar do recall ser mais importante, foi adotado o \textit{f1-score} como critério, pois o ajuste no \textit{trade-off} pode ser feito manualmente e a 
critério de um tomador de decisão,
usando a curva ROC ou \textit{precisão-recall}. Em caso de empate será usado o \textit{recall}. 

Para estes casos, será analisada a matriz de confusão, onde poderá ser feito a análise dos tipos de erros e acertos e as curvas de \textit{precisão-recall}, 
para averiguar o impacto da precisão e recall em diferentes \textit{folds} e como os modelos se comparam com o \textit{baseline}.

Então, será eleito o melhor modelo considerando o maior \textit{f1-score} médio. Nesta etapa, é importante analisar também o desvio padrão; é desejável 
que o melhor modelo não tenha apenas um \textit{f1-score} médio alto, mas um desvio padrão baixo, indicando maior estabilidade.

Por fim, será feita a comparação dos modelos com os apresentados na revisão da literatura.

\section{Resultados do modelo GRU}
\label{sec:resultados_gru}

Na Tabela~\ref{tab:resultado_cv_gru_validacao} é mostrado o resultado médio do modelo GRU puro na validação junto com os respectivos desvio padrão.

\begin{table}[H]
\centering
\caption{Média das métricas do GRU para a classificação normal vs. ventricular na validação}
\label{tab:resultado_cv_gru_validacao}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Média} & \textbf{Desvio Padrão} \\
\hline
Precisão & 0,8515 & 0,1825 \\
\textit{Recall} & 0,8039  & 0,0795 \\
\textit{F1-Score} & 0,8060 & 0,0760 \\
Acurácia & 0,9640 & 0,0278 \\
\hline
\end{tabular}
\legend{Fonte: Elaborado pelo autor.}
\end{table}

Os resultados indicam que o modelo achou aproximadamente 80\% dos casos positivos, com um desvio padrão relativamente baixo, indicando boa estabilidade.
Além disso, a precisão do modelo foi maior que seu \textit{recall}, indicando um perfil mais conservador na classificação. 

A seguir os resultados no treino:

\begin{table}[H]
\centering
\caption{Média das métricas do GRU para a classificação normal vs. ventricular no treino}
\label{tab:resultado_cv_gru_treino}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Média} & \textbf{Desvio Padrão} \\
\hline
Precisão & 0,9872 & 0,0121 \\
\textit{Recall} & 0,9782 & 0,0150 \\
F1-Score & 0,9827 & 0,0134 \\
Acurácia & 0,9969 & 0,0024 \\
\hline
\end{tabular}
\legend{Fonte: Elaborado pelo autor.}
\end{table}

Comparando os resultados do treino na Tabela~\ref{tab:resultado_cv_gru_cnn_treino} com os resultados da validação na Tabela~\ref{tab:resultado_cv_gru_cnn_validacao},
observa-se um diferença substancial; evidenciando sobreajuste, isto é, o modelo apresentou uma baixa capacidade de generalização para pacientes não vistos.

Esse fenômeno ocorre pois modelos com alta flexibilidade, como redes neurais, conseguem se ajustar intimamente com os dados de treino.
Caso eles não sejam representativos da população, tais modelos podem aprender ruído e particularidades dessa amostra ao invés de padrões generalizáveis.

No contexto do MIT-BIH, o desbalanceamento das classes pode ter causado isso. Como há poucos exemplos da classe positiva, é fácil para o modelo memorizar
padrões morfológicos e rítmicos das arritmias do conjunto de treino, falhando ao encontrar variações dessas instâncias em pacientes diferentes.
Conforme descrito nas seções \ref{sub_sec:padroes_arritmias_aami} e também em \ref{sec:particionamento}, existe uma grande variação 
entre as arritmias, tanto de paciente para paciente quanto intra-paciente.

Outra evidência é a diferença entre a acurácia média do conjunto de treino em relação ao conjunto de validação. Observa-se uma 
diferença significantemente menor. Esta métrica é dominada pela classe negativa, indicando que o modelo conseguiu aprender padrões mais generalizáveis
ao ser exposto a mais exemplos dessa classe. 

Diferente da acurácia, as demais métricas são muito mais sensíveis ao desempenho na classe positiva.

O particionamento usado torna a tarefa de generalização mais desafiadora, pois o modelo é avaliado com ECGs não vistos
durante o treino.

Na Figura~\ref{fig:gru_resultados_por_fold}, está os resultados alcançado pelo modelo em cada \textit{fold} na validação:

\begin{figure}[H]
  \centering
  \caption{Métricas do modelo GRU por \textit{fold}}
   \includegraphics[width=1.0\textwidth]{figuras/modelos_resultados/gru/gru_metricas_por_fold.png} % insere o tikzpicture puro
  \label{fig:gru_resultados_por_fold}
    \legend{Fonte: Elaborado pelo autor.}
\end{figure}

No \textit{fold} três, o modelo obteve sua menor precisão, aproximadamente 0,51 porém obteve um alto \textit{recall}, aproximadamente 0,96.
Essa discrepância sugere que neste \textit{fold}, havia batimentos normais que fugiam do padrão aprendido no treino, fazendo com que o modelo
confundisse eles com batimentos da classe ventricular. Nos demais \textit{folds}, a precisão foi maior que o \textit{recall}, sugerindo a presença 
de arritmias com características mais sutis, que fizeram com que o modelo as confundissem com batimentos normais.

Considerando o \textit{f1-score}, o terceiro \textit{fold} foi eleito o pior. Como o \textit{fold} cinco empatou com o segundo por 
esse mesmo critério, como desempate, aquele com o maior \textit{recall}, o quinto, foi considerado o melhor. 

\subsection{Resultados no pior e melhor caso (Modelo GRU)}

Na Figura~\ref{fig:matriz_confusao_melhor_fold_gru}, está a matriz de confusão do modelo em seu melhor \textit{fold}:

\begin{figure}[H]
  \centering
  \caption{Matriz de confusão do modelo GRU em seu melhor \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru/matriz_confusao_melhor_fold_gru_alt.png} % insere o tikzpicture puro
  \label{fig:matriz_confusao_melhor_fold_gru}
    \legend{Fonte: Elaborado pelo autor.}
\end{figure}

Na matriz, é possível ver o desbalanceamento das classes. Neste \textit{fold}, o número de sequencias pertencentes a classe
negativa é 9.088, enquanto que 1.384 pertencem a positiva; ou seja, aproximadamente, 13,21\% de todas as sequencias são
da classe positiva. 

A maioria dos erros cometidos são de falsos negativos; o modelo classificou 310 sequencias arrítmicas como normais e 
apenas duas normais como arrítmicas. Algo que já era evidenciado no gráfico \ref{fig:gru_resultados_por_fold}, pois 
sua precisão foi maior que seu \textit{recall}.

%O modelo achou 78\% das arritmias. Porém no pior, como pode ser visto na figura \ref{fig:ap_gru_pior_fold}, o modelo conseguiu achar 96\% das arritmias.
Na Figura~\ref{fig:matriz_confusao_pior_fold_gru}, é dada a matriz de confusão no pior \textit{fold}

\begin{figure}[H]
  \centering
  \caption{Matriz de confusão do modelo GRU em seu pior \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru/matriz_confusao_pior_fold_gru_alt.png} % insere o tikzpicture puro
  \label{fig:matriz_confusao_pior_fold_gru}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

Aqui o desbalanceamento foi mais severo; havia 9.209 classes negativas e 955 classes positivas; 9,39\% aproximadamente. 
Neste \textit{fold}, a situação se inverte: a maioria dos erros foram de falsos positivos, confirmando o que foi visto no 
gráfico \ref{fig:gru_resultados_por_fold}.

%As duas figuras ilustram como o modelo conseguiu aprender melhor a classe negativa do que a classe positiva; evidenciado pelo fato dele confundir
%muito menos negativo com positivo do que o contrário. Um resultado esperado devido a essa ser a classe dominante em todos os \textit{folds}.

\iffalse
A seguir, na figura \ref{fig:roc_cnn_gru_melhor_fold}, a curva ROC no melhor \textit{fold}. Conforme discutido na seção \ref{sec:metricas},
esta curva mostra os diferentes valore do \textit{recall} e do FRP para todos os possíveis limiares de decisão.

\begin{figure}[H]
  \centering
  \caption{Curva \textit{ROC} modelo GRU em seu melhor \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru/roc_gru_melhor_fold.png} % insere o tikzpicture puro
  \label{fig:roc_melhor_fold_gru}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

Considerando que o \textit{baseline}, um classificador aleatório, tem uma \textit{AUC} de 0,5, o melhor foi significantemente melhor.
O gráfico mostra ainda que o modelo consegue ter um \textit{recall} de quase 80\% ao custo de um FPR de 0\%; ou seja, ele não comete 
erros de falso positivo. Para além desse valor, o modelo começaria a cometer tais erros, aumentando o FPR.

\begin{figure}[H]
  \centering
  \caption{Curva \textit{ROC} do modelo GRU em seu pior \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru/roc_gru_pior_fold.png} % insere o tikzpicture puro
  \label{fig:roc_pior_fold_gru}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

No pior fold, \ref{fig:roc_pior_fold_gru}, o modelo ainda conseguiu manter uma performance satisfatória, com um \textit{AUC} de 0,93. 
Neste caso, o modelo tem um \textit{recall} de quase 100\% enquanto mantém um FPR de menos de 20\%. Além desse valor, o \textit{recall}
cresce devagar conforme o erro aumenta, comportamento diferente do observado no pior caso.

Entretanto, devido ao desbalanceamento dos conjuntos, o desempenho pode ser melhor analisado com a curva PR. Conforme a seção \ref{sec:metricas},
esse gráfico mostra os diferentes valores do \textit{recall} e da precisão para todos os possíveis limiares de decisão.
\fi

Na Figura~\ref{fig:ap_cnn_gru_pior_fold} é ilustrada a curva PR do modelo em seu pior \textit{fold}. Conforme a seção~\ref{sec:metricas},
este gráfico mostra os diferentes valores do \textit{recall} e da precisão para todos os possíveis limiares de decisão.

\begin{figure}[H]
  \centering
  \caption{Curva precisão vs \textit{recall} do modelo GRU em seu pior \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru/ap_gru_pior_fold.png} % insere o tikzpicture puro
  \label{fig:ap_gru_pior_fold}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

O \textit{baseline} no pior caso foi de aproximadamente 9,39\%, contrastando com o 49\% alcançado pelo modelo. Entretanto, a precisão foi baixa. Pelo gráfico, é possível ver que, por exemplo, seria 
possível ter um recall de 80\% porém com uma precisão menor que 60\%; ou seja, o modelo encontra 80\% das arritmias, porém, menos de 60\%
de todas as sequências classificadas como arrítmicas realmente são arrítmicas. Neste \textit{fold}, a AUC foi 0,93, maior que o 
\textit{baseline} de 0,5.

Na Figura~\ref{fig:ap_gru_melhor_fold}, ilustra-se a mesma curva porém no melhor \textit{fold}.

\begin{figure}[H]
  \centering
  \caption{Curva precisão vs \textit{recall} do modelo GRU em seu melhor \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru/ap_gru_melhor_fold.png} % insere o tikzpicture puro
  \label{fig:ap_gru_melhor_fold}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

Neste cenário, o modelo alcançou um \textit{AUCPR} de 80\%, enquanto que a proporção de casos positivos foi de 13,21\%.
A precisão do modelo mantém-se alta para \textit{recall} abaixo de 80\%; quase 100\%. Porém, a precisão cai drasticamente, 
menor que 20\%, quando o \textit{recall} ultrapassa essa faixa. 

O AUC do modelo foi de 0,89, maior que o \textit{baseline} de 0,5.

Portanto, apesar do desbalanceamento, o modelo alcançou resultados satisfatórios, considerando o extremo desbalanceamento do conjunto.

\section{Resultados do modelo híbrido GRU e CNN}
\label{sec:resultados_gru_cnn}

O modelo híbrido apresentou resultado superior em relação ao modelo anterior. Na Tabela~\ref{tab:resultado_cv_gru_cnn_validacao}
abaixo, é possível ver que o modelo obteve média maior em todas as métricas. Apesar disso, o modelo obteve um desvio padrão maior 
no \textit{recall} e \textit{F1-score}, mas a diferença foi de apenas 0.0106 e 0.0062, respectivamente.

\begin{table}[H]
\centering
\caption{Média das métricas do modelo híbrido CNN e GRU para a classificação normal vs. ventricular na validação}
\label{tab:resultado_cv_gru_cnn_validacao}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Média} & \textbf{Desvio Padrão} \\
\hline
Precisão & 0,8800 &  0,1684 \\
\textit{Recall} & 0,8726  & 0,0857 \\
\textit{F1-Score} & 0,8593 & 0,0866 \\
Acurácia & 0,9730 & 0,0258 \\
\hline
\end{tabular}
\legend{Fonte: Elaborado pelo autor.}
\end{table}

Na Tabela~\ref{tab:resultado_cv_gru_cnn_treino}, é possível observar que ainda há \textit{overfit} porém a diferença entre os resultados
do treino e validação do modelo híbrido é menor quando comparado com o modelo GRU puro. Por exemplo, a 
diferença relative entre o \textit{f1-score} de treino e validação para o modelo híbrido foi de aproximadamente 9,56\% 
enquanto que para o modelo recorrente puro, foi de, aproximadamente, 17,98\%.

\begin{table}[H]
\centering
\caption{Média das métricas do modelo híbrido CNN e GRU para a classificação normal vs. ventricular no treino}
\label{tab:resultado_cv_gru_cnn_treino}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Média} & \textbf{Desvio Padrão} \\
\hline
Precisão & 0,9698 &  0,0180 \\
\textit{Recall} & 0,9313  & 0,0268 \\
\textit{F1-Score} & 0,9502 & 0,0222\\
Acurácia & 0,9915 & 0,0035 \\
\hline
\end{tabular}
\legend{Fonte: Elaborado pelo autor.}
\end{table}

Na Figura~\ref{fig:gru_cnn_resultados_por_fold}, estão os resultados obtidos pelo modelo híbrido em cada \textit{fold}.

\begin{figure}[H]
  \centering
  \caption{Métricas do modelo híbrido CNN e GRU por \textit{fold}}
   \includegraphics[width=1.0\textwidth]{figuras/modelos_resultados/gru_cnn/gru_cnn_metricas_por_fold.png} 
  \label{fig:gru_cnn_resultados_por_fold}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

O modelo manteve a tendencia de ter uma precisão acima do \textit{recall} na maioria dos \textit{folds}. É possível observar também que o modelo
obteve um \textit{recall} maior que o modelo GRU puro em todos os \textit{folds} e uma precisão, no geral, maior ou igual. Sendo as exceções,
os \textit{folds} quatro e cinco, porém a diferença foi de, aproximadamente, 0,01 pontos percentuais. 

A seguir, o desempenho do modelo em seu melhor e pior \textit{fold}. Repetindo os critérios descritos na seção \ref{sec:resultados_gru}, o melhor
\textit{fold} foi o segundo e o pior foi o terceiro.

\subsection{Resultados no pior e melhor caso (Modelo Híbrido)}

Na Figura~\ref{fig:matriz_confusao_cnn_gru_melhor_fold}, é ilustrada a matriz de confusão do modelo em seu melhor \textit{fold}.
Neste cenário, o modelo não cometeu nenhum erro de falso negativo, mas 41 de falso positivo. Além de ter acertado 511 arritmias 
e 3.968 batimentos normais.

\begin{figure}[H]
  \centering
  \caption{Matriz de confusão modelo híbrido CNN e GRU em seu melhor \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru_cnn/matriz_confusao_melhor_fold_gru_cnn_1_alt.png} 
  \label{fig:matriz_confusao_cnn_gru_melhor_fold}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

Como pode ser visto no gráfico; o modelo não cometeu nenhum erro de falso positivo e errou 41 arritmias, classificando-as
como batimentos normais. Neste \textit{fold}, a classe positiva compõe, aproximadamente 12,23\% do total. Assim, sendo 
levemente menos balanceado que o melhor \textit{fold} do modelo GRU puro, que tinha 13,21\% de classes positivas, e com um desempenho superior: com um \textit{f1-score}
de 0,97 contra 0,87. 

Já no pior \textit{fold}, Figura~\ref{fig:matriz_confusao_cnn_gru_pior_fold}, a situação se inverte,
a quantidade de erros de falsos negativos, oito, foi menor que as de falsos positivos, 776, refletindo em um
\textit{recall} maior que a precisão; como foi observado no gráfico \ref{fig:gru_cnn_resultados_por_fold}.

\begin{figure}[H]
  \centering
  \caption{Matriz de confusão modelo híbrido CNN e GRU em seu pior \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru_cnn/matriz_confusao_pior_fold_gru_cnn_3_alt.png} 
  \label{fig:matriz_confusao_cnn_gru_pior_fold}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

Na Figura~\ref{fig:ap_cnn_gru_pior_fold} ilustra a curva PR do modelo híbrido em seu pior caso. Comparando com o pior caso 
do modelo GRU, na Figura~\ref{fig:ap_gru_pior_fold}, o modelo híbrido mantém um \textit{recall} maior para os mesmos valores 
de precisão. Em ambos os casos, a precisão quando o \textit{recall} é maior ou igual a um valor próximo a 100\%, porém no modelo puro, isso 
ocorre bem antes. o AP também foi maior; cerca de 0,55 contra 0,49. No piro caso, o AUC do modelo híbrido foi de 0,95, contra 0,93 do 
modelo GRU puro.

\begin{figure}[H]
  \centering
  \caption{Curva precisão vs \textit{recall} do modelo híbrido CNN e GRU em seu melhor \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru_cnn/ap_gru_cnn_pior_fold_3.png} 
  \label{fig:ap_cnn_gru_pior_fold}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

Já a Figura~\ref{fig:ap_cnn_gru_pior_fold} ilustra o melhor caso do modelo híbrido. O AP foi de 0,96 enquanto que o \textit{baseline} seria de aproximadamente
12,23\% e, além disso, o AP foi maior que o obtido pelo GRU puro; que foi de 0,83.

\begin{figure}[H]
  \centering
  \caption{Curva precisão vs \textit{recall} do modelo híbrido CNN e GRU em seu melhor \textit{fold}}
   \includegraphics[width=0.6\textwidth]{figuras/modelos_resultados/gru_cnn/ap_gru_cnn_melhor_fold_1.png} 
  \label{fig:ap_cnn_gru_melhor_fold}
  \legend{Fonte: Elaborado pelo autor.}
\end{figure}

No melhor caso, o modelo mantém uma precisão próxima de 100\% dentro de uma faixa de \textit{recall} que chega próximo aos 85\%. O AUC
foi de 0,96, maior que o \textit{baseline} de 0,5 e do modelo puro, que foi de 0,89

De modo geral, os modelos exibiram um perfil semelhante em seu pior e melhor caso. No pior, a sensibilidade foi maior, resultados
em maiores erros de falso positivo, como resultado, o \textit{recall} foi alto e a precisão foi baixa. No melhor caso, houve um 
equilíbrio maior e, apesar do \textit{recall} mais baixo, a alta precisão aumentou o \textit{f1-score}.

Esse ganho de desempenho sugere que o uso da CNN para extração de \textit{features} morfológicas pode ter sido uma vantagem. A 
camada recorrente do modelo híbrido não precisou aprendê-las do sinal, apenas precisou se concentrar em como elas se encaixam 
no contexto da sequência.

\section{Conclusão dos resultados}

Nesta seção, foi apresentado os resultados obtidos pelos modelos GRU puro e híbrido. Ambos os modelos apresentaram um caso de \textit{overfit},
evidenciado pela grande diferença entre o desempenho no treino com o da validação. A partir das métricas individuais em cada \textit{fold},
foi identificado o pior e melhor caso. Neste primeiro, ambos os modelos tiveram uma precisão bem menor que seu \textit{recall}, invertendo a 
tendência apresentada nos outros \textit{folds}. O que pode ter sido devido a batimentos normais com características destoantes das aprendidas
no treino, fazendo com que os modelos os confundissem com batimentos arrítmicos. 

Em contextos médicos, é preferível um \textit{recall} maior, pois falsos negativos são mais danosos que um falso positivo; isto é, é melhor
dizer que um batimento normal é arrítmico do que o contrário. Entretanto, uma precisão muito baixa pode indicar que o modelo é 
tão bom quanto um modelo aleatório; o que o tornaria inútil. 

Entretanto, os APs dos modelos no pior caso evidenciou que eles superaram esse \textit{baseline}, indicando que foi aprendido padrões que lhes permitem classificar as arritmias, entretanto, esses padrões ainda não são 
perfeitamente generalizáveis.

Conforme apresentado, existe um desbalanceamento entre as classes. Uma forma de contornar esse problema é o uso de "pesos" na função de 
custo para penalizar mais erros na classe minoritária. Seu uso no modelo GRU puro não surtiu o efeito desejado; o \textit{f1-score}
médio, por exemplo, foi de 0,7750 com desvio padrão de 0,1552 contra 0,8060 e desvio padrão de 0,0760; é menor e mais instável.
Uma hipótese está no seu mecanismo de funcionamento. 
Quando se observa as precisão e \textit{recall} do modelo no treino; nota-se um alto desempenho, ou seja, o modelo "prestou" atenção na 
classe minoritária. Assim, uma possível causa é, na verdade, a possível diferença morfológica entre as arritmias de diferentes pacientes.
Neste sentido, o uso de pesos não ajudaria o modelo.

Por fim, na tabela a seguir é resumido os resultados alcançados pelos modelos e os apresentados na seção \ref{sec:trabalhos_correlatos}.
Devido as diferenças metodológicas, a comparação direta entre os resultados não é possível. Além do mais, devido ao sobreajuste 
observado em ambos os modelos, optou-se por não realizar o teste final no Ds2, pois este é um teste único feito quando 
se tem um modelo com um desempenho satisfatório.

\input{includes/revisao_literatura_tabela_resultados}

\input{inputs/analise_de_erros}